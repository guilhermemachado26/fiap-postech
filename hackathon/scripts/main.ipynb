{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Installing the dependencies.\n",
    "\"\"\"\n",
    "\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Read the dataset and transform the labels to 0 or 1.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"image_labels.csv\")\n",
    "df['label'] = LabelEncoder().fit_transform(df['label'])\n",
    "df[\"label\"] = df[\"label\"].replace({0: 1, 1: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the dataset into train, validation and test sets.\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['filename'], df['label'], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read, resize and load images.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images(image_paths, img_size=(224, 224)):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "X_train = load_images(X_train)\n",
    "X_val = load_images(X_val)\n",
    "X_test = load_images(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 55s 329ms/step - loss: 1.7137 - accuracy: 0.9268 - val_loss: 1.5354 - val_accuracy: 0.9229\n",
      "45/45 [==============================] - 8s 176ms/step - loss: 1.5187 - accuracy: 0.9250\n",
      "Test accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers[:100]:  \n",
    "    layer.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Aumentei o dropout para regularização\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=out)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=32)\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test accuracy: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use the model to detect dangerous objects in a video.\n",
    "\"\"\"\n",
    "\n",
    "def detect_objects_in_video(video_path, model, threshold=0.5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        img = cv2.resize(frame, (224, 224)) / 255.0\n",
    "        pred = model.predict(np.expand_dims(img, axis=0))[0][0]\n",
    "        \n",
    "        label = 'DANGEROUS' if pred > threshold else 'SAFE'\n",
    "        color = (0, 0, 255) if pred > threshold else (0, 255, 0)\n",
    "        cv2.putText(frame, label, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        cv2.imshow('Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_objects_in_video(\"video.mp4\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method to show the gradient CAM (Class Activation Map) for the model.\n",
    "Shows where the model paid attention to in the image to make the prediction.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def grad_cam(model, image, layer_name):\n",
    "    img_array = np.expand_dims(image, axis=0) / 255.0\n",
    "    grad_model = Model(inputs=model.input, outputs=[model.get_layer(layer_name).output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]  # Como temos saída binária, usamos a primeira (facas)\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]  # Gradientes da camada\n",
    "    weights = np.mean(grads, axis=(0, 1))\n",
    "\n",
    "    cam = np.dot(conv_outputs[0], weights)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    cam = cv2.resize(cam, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    heatmap = np.uint8(255 * cam)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    final_image = cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"basket.png\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "\n",
    "layer_name = \"Conv_1\"\n",
    "result = grad_cam(model, image, layer_name)\n",
    "\n",
    "cv2.imshow(\"Grad-CAM\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
